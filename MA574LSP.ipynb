{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b1830b",
   "metadata": {},
   "source": [
    "# Least Square Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7c5d5",
   "metadata": {},
   "source": [
    "## Overdetermined Linear System of Equations\n",
    "---\n",
    "Consider the following system of $m$ linear equations in $n$ variables.\n",
    "\\begin{align}\n",
    "a_{11} x_1 + a_{12} x_2  + \\cdots + a_{1n} x_n  &= b_1 \\\\\n",
    "a_{21} x_1 + a_{22} x_2  + \\cdots + a_{2n} x_n  &= b_2 \\\\\n",
    " \\vdots \\qquad \\qquad   & \\ \\\\\n",
    "a_{m1} x_1 + a_{m2} x_2  + \\cdots + a_{mn} x_n  &= b_ m,\n",
    "\\end{align}\n",
    "\n",
    "-  The solution of a linear system represents the **point of intersection of hyperplanes** given by the lienar equations.\n",
    "\n",
    "\n",
    "-  The solution also represents the **linear coding of the columns** of a matrix $A$ to get a vector $b$ in the column space ($\\mathcal{C}(A)$).\n",
    " \n",
    "$$\n",
    " x_1 \\begin{pmatrix}a_{11}\\\\a_{21}\\\\ \\vdots \\\\a_{m1}\\end{pmatrix} +\n",
    " x_2 \\begin{pmatrix}a_{12}\\\\a_{22}\\\\ \\vdots \\\\a_{m2}\\end{pmatrix} +\n",
    " \\cdots +\n",
    " x_n \\begin{pmatrix}a_{1n}\\\\a_{2n}\\\\ \\vdots \\\\a_{mn}\\end{pmatrix}\n",
    " =\n",
    " \\begin{pmatrix}b_1\\\\b_2\\\\ \\vdots \\\\b_m\\end{pmatrix}\n",
    " $$\n",
    " \n",
    " or simply as\n",
    " $$\n",
    " x_1 A_{:1}+x_2 A_{:2}+ \\cdots +x_n A_{:n} = \\mathbf{b}\n",
    " $$\n",
    " \n",
    "\n",
    "- The system could be represented in a compact form as $A\\mathbf{x} = b$, where \n",
    " $$\n",
    " A=\n",
    "\\begin{pmatrix}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n} \\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{pmatrix},\\quad\n",
    "\\mathbf{x}=\n",
    "\\begin{pmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{pmatrix},\\quad\n",
    "\\mathbf{b}=\n",
    "\\begin{pmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "\\vdots \\\\\n",
    "b_m\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9caac6",
   "metadata": {},
   "source": [
    "- The system is called...\n",
    "  >- **Square system** when $m = n$. Admits a unique solution only when $A$ is invertible.\n",
    "     \n",
    "  >- **overdetermined** when $m > n$.\n",
    "  \n",
    "  >- **underdetermined** when $ m < n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda5d1f",
   "metadata": {},
   "source": [
    "**Question** Pick up all the correct statements\n",
    "\n",
    "   A. Commonly, an over-determined system does not have any solutions.\n",
    "   \n",
    "   B. No over-determined system has any solution.\n",
    "   \n",
    "   C. An underdetermined system has infinite many solutions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ff496",
   "metadata": {},
   "source": [
    "### Least Square Problems (LSP)\n",
    "When $m > n$ the number of variables is less than the number of equations. These systems are rarely exactly solvable. However, in an approximate sense, we would like to find a vector $A\\mathbf{x}$ in the column space of $A$ which is closest to $\\mathbf{b}$. In such a case, we aim to find $\\mathbf{x}$ such that the residual vector $\\mathbf{r}=\\mathbf{b}-A\\mathbf{x}$ as small as possible.\n",
    "<img src=\"https://live.staticflickr.com/65535/52739576429_a0be07aed5_z.jpg\" width=\"320\" height=\"214\" alt=\"LSProj\" align=\"right\" />\n",
    "<div class=\"alert alert-success\"> \n",
    "    \n",
    "<strong> LSP Formulation </strong>\n",
    "    \n",
    "For $A  \\in \\mathbb{R}^{m \\times n}$ (where $m \\geq n$) and $\\mathbf{b} \\in \\mathbb{R}^m$, find the vector $\\mathbf{x} \\in \\mathbb{R}^n$ that minimize\n",
    "$$\n",
    "    \\underset{\\mathbf{x} \\in \\mathbb{R}^n}{\\operatorname{minimize}}  \\|A \\mathbf{x} - \\mathbf{b}\\|^2_2\n",
    "$$\n",
    "</div>    \n",
    "<span style='font-size:50px;'>&#129300;</span> Why should we use $l_2$ norm and not some other norms such as $l_1$ or $l_{\\infty}$ norm?\n",
    "\n",
    "<button data-toggle=\"collapse\" data-target=\"#demo\">Show why</button>\n",
    "\n",
    "<div id=\"demo\" class=\"collapse\">\n",
    "The function is differentiable in $l_2$ norm. Moreover, orthogonal transformations could be used as $l_2$ norms are invariant under multiplication of the vectors by orthogonal matrices. This leads to better numerical solutions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a721be",
   "metadata": {},
   "source": [
    "Please note the equivalent formulation of the minimizer as\n",
    "\n",
    "$$\\large \\bbox[10px, #90caf9, border: 1px solid gray]{\n",
    "\\hat{\\mathbf{x}} = \\underset{\\mathbf{x} \\in \\mathbb{R}^n}{\\operatorname{argmin}} (\\mathbf{b}-A\\mathbf{x})^T(\\mathbf{b}-A\\mathbf{x})\n",
    "}$$\n",
    "\n",
    "\n",
    "<span style='font-size:50px;'>&#9971;</span> Note that from our discussion on matrix calculus and optimization, the gradient of the above function was found to be $A^T(A\\mathbf{x}-\\mathbf{b})$ which also leads to the normal equations discussed ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a5752",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "<strong>Theorem</strong>\n",
    "<p>The vector $\\mathbf{x} \\in \\mathbb{R}^n$ minimizes the residual norm, $\\| \\mathbf{r} \\| = \\|\\mathbf{b} - A \\mathbf{x}\\|_2$, if and only if $\\mathbf{r} \\perp \\text{col}(A)$.\n",
    " </p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48312583",
   "metadata": {},
   "source": [
    "<div style=\"display:inline;float:left;\" width=\"60%\">\n",
    "It follows from the above theorem that\n",
    "$$ \\mathbf{r} \\perp col(A) \\implies \\mathbf{r} \\in N(A^T) $$ as column space and left-null space are orthogonal.( Recall $\\mathcal{C}(A)\\oplus \\mathcal{N}(A^T)=\\mathbb{R}^m$. )\n",
    "\n",
    "This implies that \n",
    "\n",
    "\\begin{align*}\n",
    "\t&A^{T}\\mathbf{r} = 0 \\\\\n",
    "\t&A^{T}(\\mathbf{b}-A\\mathbf{x}) = 0 \\\\\n",
    "\t&A^{T}A\\mathbf{x} = A^{T}\\mathbf{b}\n",
    "\\end{align*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca5d45",
   "metadata": {},
   "source": [
    "Which naturally leads us to the **normal equations**\n",
    "$$\\large \\bbox[15px, #90caf9, border: 1px solid gray]{\n",
    "A^TA \\mathbf{x} = A^T \\mathbf{b}.\n",
    "}\n",
    "$$\n",
    "Note, the computation above attempts to demonstrate how the normal equations solve the LSP problem by minimizing the residual norm.\n",
    "\n",
    "**Discussion** The condition number while solving the normal equations.\n",
    "\n",
    "The **condition number** of rectangular matrix $B$ of rank $r$ could be given by\n",
    "$$\\large \\bbox[10px, #90caf9, border: 1px solid gray]{\n",
    "\\kappa(B) = \\frac{\\sigma_1(B)}{\\sigma_r(B)}\n",
    "}\n",
    "$$\n",
    "\n",
    "The condition number for the systems of normal eqaution thus comes out to be $\\kappa(A^TA) = \\frac{\\sigma_1^2}{\\sigma_r^2} = [\\kappa(A)]^2$\n",
    "\n",
    "<span style='font-size:50px;'>&#10071;</span> High condition number for $A$ suggest trouble in the case of nearly rank-deficient problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd71515",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "<strong>Theorem</strong>\n",
    "    <p>For $A  \\in \\mathbb{R}^{m \\times n}$  (where $m \\geq n$)  and $\\mathbf{b} \\in \\mathbb{R}^m$, if the vector $\\mathbf{x} \\in \\mathbb{R}^n$ satisfies the condition $A^{T}A\\mathbf{x} = A^{T}\\mathbf{b}$, then $\\mathbf{x}$ solves the least square problem.\n",
    "        </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26650536",
   "metadata": {},
   "source": [
    "**Example**: Solve the following system in the least square sense\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "3x+2y &=3\\\\\n",
    "2x+3y &=0\\\\\n",
    "x+2y &=1\n",
    "\\end{align}\n",
    "$$\n",
    "Or, in matrix-vector form\n",
    "$$\n",
    " \\underbrace{\\begin{pmatrix} 3 & 2 \\\\ 2 & 3  \\\\1 & 2 \\end{pmatrix}}_{A}\n",
    "\\underbrace{\\begin{pmatrix} x \\\\ y  \\end{pmatrix}}_{\\mathbf{x}} = \\underbrace{\\begin{pmatrix} 3 \\\\ 0 \\\\ 1 \\end{pmatrix}}_{\\mathbf{b}}\n",
    "$$\n",
    "We have the normal equations $A^{T}A\\mathbf{x} = A^{T}\\mathbf{b}$\n",
    "$$\n",
    "\\begin{pmatrix} 14 & 14\\\\ 14 & 17 \\end{pmatrix}\\mathbf{x} = \\begin{pmatrix} 10\\\\8\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "By using Gaussian elimination, we have\n",
    "$$\n",
    "\\begin{pmatrix} 14 & 14 & \\vdots & 10\\\\ 14 & 17 & \\vdots & 8\\end{pmatrix}\\longrightarrow \\begin{pmatrix} 14 & 14 & \\vdots & 10\\\\ 0 & 3 & \\vdots & -2\\end{pmatrix}\n",
    "$$\n",
    "The last row from above gives $3x_2=-2 \\Rightarrow x_2=-\\frac{2}{3}$. \n",
    "\n",
    "From the first row we get $x_1(10-14(-2/3))/14=\\frac{29}{21}$.\n",
    "\n",
    "**Homework** Find the vector $\\mathbf{x}=(x_1,\\, x_2)^T$ that solves the following system in the least square sense\n",
    "$$\n",
    " \\begin{pmatrix} 1 & 2 \\\\ 1 & -1  \\\\1 & 3 \\end{pmatrix}\n",
    "\\begin{pmatrix} x_1 \\\\ x_2  \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\\\ 0 \\end{pmatrix}\n",
    "$$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02cb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
